Reading is for losers.

Monte Carlo is our best friend.

"to combine the sampling of a continuous probability distribution (using ‘MCMC’) with the idea of Bayesian evidence to numerically determine which model is preferred as an explanation for a dataset"
Sections 4.1 and 5.1 of Statistical Techniques in Cosmology by Prof. Alan Heavens
https://arxiv.org/pdf/0906.0664v3.pdf

1. Data Generator
2. Model Selector
3. Test Model Selector against real data
4. Take over the world
5. Space colonisation

Timeline:
20161018
Meeting with Prof. Heavens

20161019
Worked on data generator
Able to generate arrays of points sampled from a Gaussian distribution, created histograms and scatterplots from data generated. Histograms can work for N dimensions, but a single scatterplot can visualise maximum 3 dimensions. 
Only using the graphs to show that data generator works. 
Began thinking about nearest neighbour problem.
Nearest neighbours: https://www.dataquest.io/blog/k-nearest-neighbors-in-python/
Nearest neighbours (but with a part regarding self learning): https://blog.cambridgecoding.com/2016/01/16/machine-learning-under-the-hood-writing-your-own-k-nearest-neighbour-algorithm/
Lambda functions: http://stackoverflow.com/questions/890128/why-are-python-lambdas-useful
Made nearest neighbour program
Research nearest neighbour constant of proportionality with number density?

20161021
Couldn't find nearest neighbour constant of proportionality with number density yet.
Have no other solution for the program other than to run through every single point and calculate the distance between itself and every other point.
Other possibilities: 1. Separate into cells/sectors. But problem with that is that nearest neighbour may not be in the same cell as Heavens said because real data will be very scattered and large. 2. K nearest neighbours method. But to do that we would have to calculate the distance between every point with every other point anyway.
Writing program which will give the number density as a function of the nearest neighbour.
Possible solutions to nearest neighbour program being slow: http://www.cs.cmu.edu/~quixote/NearestNeighbor.pdf
Wrote program to calculate constant of proportionality between number density / nearest neighbour distance and probability.
Maybe we need to just find our own constant of proportionality, since we need the number density for every point, use the nearest neighbour distance for each point to find the "volume" which is just the sphere with radius of nearest neighbour distance and then one point in that volume = number density.
But how would that work in more than 3 dimensions? -> N-spheres -> Gamma functions

20161024
Distribution of Euclidean Distances Between Randomly Distributed Gaussian Points in n-Space: https://arxiv.org/pdf/1508.02238v1.pdf
Found a list of Aj, deciding how to find the mean.

20161026
Starting work on Heaven's questions from yesterday:
- What is the form of the distribution of p(D|n) and D, in d dimensions? If not, could work it out for 2 dimensions with first principles?
- Can you estimate n-hat from D, so that n is unbiased? ( <n-hat> = n )
Nearest Neighbour Analysis in 1D: http://www.osti.gov/scitech/servlets/purl/33152-uFJqec/webviewable/


Quotes:
20161019 
"We don't care about colour"
"We can't work without histograms"

20161021
"Can do gamma functions in python. I love python." (This was soon after he said he hated python for making a list from square brackets)
